{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import git\n",
    "import string\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "from collections import defaultdict, namedtuple, OrderedDict\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../repo')\n",
    "from dbaccessor import DBAccessor\n",
    "from pythonlinting import lint_file_or_project\n",
    "from util import format_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Influences on Code Style\n",
    "\n",
    "Who is the better python programmer? Java developers or C++ developers?\n",
    "\n",
    "To answer this and other questions, over the course of the seminar \"Code Repository Mining\" in the Winter Term 2017/18 I have developed a few scripts and a small application in the hope to show some effects of programming experience when switching to another language.\n",
    "This notebook and the corresponding [repository](https://github.com/shorschig/Language_Influences_On_Codestyle) is a concise representation and documentation of my work so far.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "What can we do with such information.\n",
    "Well, first, let's focus on _what_ errors are actually made by _which_ type of programmer. For example, do Java developers have the tendency to wrap everything in classes when there is really no need for it should they get their hands on Python? Do Python developers cause memory leaks in C++ due to soem structures they often use falsely?\n",
    "If we can find such \"Design Defects\" and their correlation to previous programming experience, we have the ability to work in a way to reduce this effects beforehand: Maybe we can create a \"Python Tutorial for Java Developers\" that precisely focuses to avoid error that are oftentimes produced by such developers.\n",
    "Different communities also focus on different styles, for example in most python programs, it's all about conciseness. If we find such relations, can we see programming patterns relating o that and how can different communities influence a persons own coding style?\n",
    "\n",
    "There are much, much more open questions to answer, but let's get to the methods.\n",
    "\n",
    "## Methods\n",
    "\n",
    "### General Setup\n",
    "\n",
    "The most important prerequisite is a clone of the [GHTorrent](http://ghtorrent.org) database, storing all the commits for all the users made on GitHub. This is the data the whole script works on.\n",
    "\n",
    "Secondly, in order for this notebook to run properly, you have to setup the aforementioned [repository](https://github.com/shorschig/Language_Influences_On_Codestyle). Note the installations instructions in the README.md, __especially the config part__.\n",
    "Please adjust the import at the top according to the position of the repository in your file system.\n",
    "\n",
    "Third, you have to create the table this script works with manually if you want to change the programming languages to explore further influences. Please have a look at the current [Create Statement](https://github.com/shorschig/Language_Influences_On_Codestyle/blob/master/languages_per_author.sql) if you wonder how this table was created.\n",
    "_Note_: This is not included in the script due to the enormous runtime of the query, this may take up to a week depending on the languages you choose, as the `raw_patches` table is huge. \n",
    "\n",
    "Last but not least, this is an information for the context of the following notebook: __The programming influence that is researched here is the influence on Python code style, coming from a Java or a C++ background. Other programming language pairs can also be used based on this work, only the analyzing part of the repository (using the linter) and the table in the databse has to be adjusted.__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "with open('../repo/config.yml', 'r') as cfg:\n",
    "    config = yaml.load(cfg)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGES = ['cpp', 'java', 'python']\n",
    "TARGET_LANGUAGE = 'python'\n",
    "BG_LANGS = [l for l in LANGUAGES if l != TARGET_LANGUAGE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terms Used\n",
    "\n",
    "Just a short clarification: There are two types of programming language when I talk about this project. \n",
    "The first is the __target language__ or __secondary language__, in this case Python. This is the language we do our analysis with, analyze design defects and plot diagrams for. This is the language most of our candidates are _not_ the _most_ proficient with.\n",
    "The second is the __background language__ or __main language__, defining the background of the programmer. This is the langauge our candidates are the most proficient with and defines their background.\n",
    "\n",
    "### Data\n",
    "\n",
    "The data I worked on was provided by the [GHTorrent](http://ghtorrent.org) database. The tables mainly used were the `commits`, `raw_patches` and `projects` tables. For further information, look into the [Create Statement](https://github.com/shorschig/Language_Influences_On_Codestyle/blob/master/languages_per_author.sql) or the [database module](https://github.com/shorschig/Language_Influences_On_Codestyle/blob/master/dbaccessor.py). The latter also explains how exactly candidates are selected. This is also shortly explained in the next paragraph.\n",
    "\n",
    "### Candidates\n",
    "\n",
    "In the following text and snippets, we will have a look at the candidates for our exploration of the topics. \n",
    "A preselection was already performed when the table we're working with was created: It summarizes all the changes for all authors for our wanted programming languages.\n",
    "Now, we want to find programmers, who:\n",
    "+ have significant programming experience in our target language and\n",
    "+ have more experience in their background language than in theri target language and\n",
    "+ have _only_ significant experience in those two langauges, so we can eliminate effects from other backgrounds.\n",
    "\n",
    "(The last point constitutes an optimal case, but I try to limit my results based on this point, too.)\n",
    "\n",
    "This poses two questions for different thresholds: \n",
    "How much experience is _significant_?\n",
    "How much _more_ do they have to have programmed?\n",
    "\n",
    "#### Significance Threshold\n",
    "\n",
    "At this point, I decided to answer the first question by plotting the number of candidates at various thresholds. This threshold at this point describes LOC, or more precisely changes done in Git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal threshold of lines to have programmed at least\n",
    "db = DBAccessor(config)\n",
    "num_cands = []\n",
    "threshs = []\n",
    "for thresh in range(10, 1000, 10):\n",
    "    bg_cands = 0\n",
    "    for bg_lang in BG_LANGS:\n",
    "        bg_cands += len(db.get_candidates(bg_lang, TARGET_LANGUAGE, thresh, 1))\n",
    "    num_cands.append(bg_cands)\n",
    "    threshs.append(thresh)\n",
    "plt.plot(threshs, num_cands)\n",
    "plt.show()\n",
    "print('Peak at ', threshs[num_cands.index(max(num_cands))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see a peak at 150 changes, i chose this threshold for further experiments. Not that this curve is not monotonous as with a higher threshold, more candidates come in the set due to the fact that they are allowed to have more experience in the third language while still not being counted as a programmer of that language.\n",
    "\n",
    "#### Multiplier Threshold\n",
    "\n",
    "To answer the second question, I also plotted the corresponding number of candidates for different experience multipliers. The sinificance threshold used here are the 150 as seen before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cands = []\n",
    "threshs = []\n",
    "for thresh in range(1, 10):\n",
    "    bg_cands = 0\n",
    "    for bg_lang in BG_LANGS:\n",
    "        bg_cands += len(db.get_candidates(bg_lang, TARGET_LANGUAGE, 150, thresh))\n",
    "    num_cands.append(bg_cands)\n",
    "    threshs.append(thresh)\n",
    "plt.plot(threshs, num_cands)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to this fact that this curve is monotonously falling and there really is no unexpected peak, I just chose a threshold of 5 for the further process. This more or less ensures a significant difference in experience while still having a lot of candidates for the process.\n",
    "\n",
    "___\n",
    "\n",
    "After the thresholds for the candidate selection are chosen, we can take a look at the projects we want to analyze.\n",
    "\n",
    "### Project Selection\n",
    "\n",
    "#### Fetching Candidates\n",
    "\n",
    "The first step is simply to fetch all the candidates with the given thresholds from the table, including a baseline of programmers with the same background as our target language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get author_ids for every candidate\n",
    "candidates = {}\n",
    "for bg_lang in BG_LANGS:\n",
    "    candidates[bg_lang] = [c[0] for c in db.get_candidates(bg_lang, TARGET_LANGUAGE)]\n",
    "candidates[TARGET_LANGUAGE] = [c[0] for c in db.get_baseline_programmers(TARGET_LANGUAGE)]\n",
    "for bg_lang, cands in candidates.items():\n",
    "    print('{} {} candidates found.'.format(len(cands), bg_lang))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching projects\n",
    "\n",
    "Next, we want to find the projects for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = defaultdict(set)\n",
    "\n",
    "for lang in LANGUAGES:\n",
    "    for candidate in candidates[lang]:\n",
    "        projects[lang].update(db.get_projects_for_user(candidate, TARGET_LANGUAGE))\n",
    "    print('{} projects for {} candidates found.'\n",
    "          .format(len(projects[lang]), lang))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some projects are not reachable. Maybe the URL is not the most recent, it was moved, set to private or other things. So let's filter them out and stick with the projects we can actually access.\n",
    "\n",
    "_Note_: Due to the amount of requests we have to send here, we need a GitHub API token. This should be in your config file. If you wonder how you can get one, look [here](https://github.com/settings/tokens). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = config['github-token']\n",
    "ghuser = config['github-user']\n",
    "Project = namedtuple('Project', ['url', 'name'])\n",
    "existing_projects = defaultdict(list)\n",
    "for lang in LANGUAGES:\n",
    "    for project in projects[lang]:\n",
    "        r = requests.get(project[0], auth=(ghuser, token))\n",
    "        obj = json.loads(r.text)\n",
    "        if 'clone_url' in obj.keys():\n",
    "            existing_projects[lang].append(Project(obj['clone_url'], project[1]))\n",
    "    print('{} projects for {} are reachable.'\n",
    "          .format(len(existing_projects[lang]), lang))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Optional:__\n",
    "#### Checking Out Projects\n",
    "\n",
    "Unless the projects are already present in the filesystem, we can check them out with git. The path and credentials like GitHub token are again taken from the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cloning repositories...')\n",
    "for lang in LANGUAGES:\n",
    "    for clone_url, name in existing_projects[lang]:\n",
    "        try:\n",
    "            git.Repo.clone_from(clone_url, config['repo-dir'] + lang + '/' +\n",
    "                                format_filename(name))\n",
    "        except:\n",
    "            print('Clone failed, maybe directory already exists.')\n",
    "print('Finished cloning.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting The Results\n",
    "\n",
    "After we successfully saved all of the projects, we can start linting them.\n",
    "\n",
    "_Attention: This step consumes a huge amount of time, be prepared before you start the next cell!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_occurences = {}\n",
    "for lang in LANGUAGES:\n",
    "    error_occurences[lang] = defaultdict(list)\n",
    "    print('Linting projects for {}:'.format(lang))\n",
    "    projects_folder = config['repo-dir'] + lang + '/'\n",
    "    for project_dir in os.listdir(projects_folder):\n",
    "        project_path = os.path.join(projects_folder, project_dir)\n",
    "        print('Linting {}'.format(project_path))\n",
    "        error_codes, num_files, num_lines = lint_file_or_project(project_path)\n",
    "        for key, val in error_codes.most_common():\n",
    "            error_occurences[lang][key].append((val, num_lines, project_path))\n",
    "print(error_occurences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing\n",
    "\n",
    "Afterwards, to better plot the results, we can easily normalize them as we already have the number of occurrences and the number of the lines that were analyzed.\n",
    "\n",
    "We're dragging the path to the project down here so that we can trace back any outliers at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_error_occurences = {}\n",
    "for lang in LANGUAGES:\n",
    "    normalized_error_occurences[lang] = {}\n",
    "    for k, v in error_occurences[lang].items():\n",
    "        normalized_error_occurences[lang][k] = [(u[0] / u[1], u[2]) for u in v]\n",
    "print(normalized_error_occurences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Optional:__\n",
    "\n",
    "#### Grouping\n",
    "\n",
    "Due to the fact that design defects falling in the category \"convention\" (error code \"C\") happen way more often than those falling in the \"refactoring\" category (error code \"R\"), it makes sense to group the occurrences by each available code. This makes looking at the plots much easier.\n",
    "\n",
    "_Note: This is currently not used in the plots at the end of this notebook, because we only plot differences for each code. This is useful if you want to plot the results for one language only._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_error_codes = defaultdict(dict)\n",
    "for lang in LANGUAGES:\n",
    "    for k, v in normalized_error_occurences[lang].items():\n",
    "        normalized_error_codes[lang][k[0][0]].update({k:v})\n",
    "print(normalized_error_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Significance\n",
    "\n",
    "Now, most importantly, we want to make plots for specific error codes to find out: Is a specific design defect more often done by a programmer with a specific background as opposed to one who doesn't have that background?\n",
    "\n",
    "In order to filter this selection a little bit, we want to apply a [significance test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test) to test the distribution of two samples. (The first idea that comes to mind concerning significance test may be the [t-test](https://en.wikipedia.org/wiki/Student%27s_t-test), but as it only works on normal distributions and there are not enough samples sometimes to even check for a normal distribution, I chose a nonparametric test for this purpose.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores the significance values of a background language compared to the target language\n",
    "target_signif = {}\n",
    "for bg_lang in BG_LANGS:\n",
    "    target_signif[bg_lang] = {}\n",
    "    for err_code in normalized_error_occurences[bg_lang].keys():\n",
    "        if err_code in normalized_error_occurences[TARGET_LANGUAGE].keys():\n",
    "            bg_data = normalized_error_occurences[bg_lang][k]\n",
    "            target_data = normalized_error_occurences[TARGET_LANGUAGE][k]\n",
    "            twosample_results = stats.mannwhitneyu(bg_data, target_data)\n",
    "            target_signif[bg_lang][err_code] = twosample_results\n",
    "    target_signif[bg_lang] = OrderedDict(sorted(target_signif[bg_lang].items(), key=lambda t: t[1][1]))\n",
    "print(target_signif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the resulting _p-value_ is less than 0.05, we can assume significance and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signifs = defaultdict(dict)\n",
    "\n",
    "for bg_lang in BG_LANGS: \n",
    "    for err_code, test_result in target_signif[bg_lang].items():\n",
    "        if test_result[1] < 0.05:\n",
    "            plot_signifs[err_code][bg_lang] = round(test_result[1], 4)\n",
    "print(plot_signifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "After we finally got all the data and analyzed for significance, we can take a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for err_code, p_vals in plot_signifs.items():\n",
    "    target_data = [e[0] for e in normalized_error_occurences[TARGET_LANGUAGE][err_code]]\n",
    "    plot_data = [target_data]\n",
    "    plot_labels = [TARGET_LANGUAGE]\n",
    "    for bg_lang in BG_LANGS:\n",
    "        if err_code in normalized_error_occurences[bg_lang].keys():\n",
    "            plot_data.append([e[0] for e in normalized_error_occurences[bg_lang][err_code]])\n",
    "            plot_labels.append(bg_lang)\n",
    "    plt.boxplot(plot_data)\n",
    "    plt.title(err_code)\n",
    "    plt.xlabel('Background')\n",
    "    plt.ylabel('Occurrences per LOC')\n",
    "    plt.xticks(range(1, len(plot_labels) + 1), plot_labels)\n",
    "    fig = plt.gcf()\n",
    "    # fig.set_size_inches(18.5, 5)\n",
    "    # plt.yscale('log')  \n",
    "    plt.show()\n",
    "    print('p-values: ', p_vals)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracing Outliers\n",
    "\n",
    "If you want to have a look at a specific outlier, you can get the path of the project by looking up the highest values (for example) in the corresponding dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_lang = 'java'\n",
    "trace_code = ('R0914', 'too-many-locals')\n",
    "# These are examples you could look up, change this according to your needs\n",
    "print([x[1] for x in sorted(normalized_error_occurences[trace_lang][trace_code], key=lambda e: e[0])])\n",
    "# This prints all projects where this error was found, ascending with the amount. Adjust this to your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Thoughts\n",
    "\n",
    "### Inaccuracies\n",
    "\n",
    "There were some assumptions I made that have a strong influence on the outcome and should maybe be adressed in future work:\n",
    "+ __Project languages__: I assumed, when creating the table I worked with, that the only programming experience a user gets is from editing a file with a specific file ending. So e.g. '.py' for Python files. This is a pretty strong limitation on actual LOC written in that specific langauge and only an approximation.\n",
    "+ __Linear experience progression__: When choosing the experience multiplier threshold, it was more or less an assumption of a linear progression of the experience. But this is not necessarily so, for example a programmer having written 5 times the amount of Python than Java does not necessarily have 5 times the experience or is a better programmer in that language. This is a topic that could further be explored.\n",
    "+ __Project contribution__: For now, when I found a candidate, I just fetch all the projects this user contributed to. This does not mean that he is the author of most of these files. It could be that he just pushed a lot of site packages to the repository or worked with other, more experienced programmers, which could distort my analysis enormously. The best way to prevent this would be doing analysis only on specific files or even changes, but then the linter has to be adjusted accordingly (a list of changes is not always valid code).\n",
    "\n",
    "So, while the topic is still an open field, this marks the end of the seminar and my work on this topic. I hope you, dear reader, enjoyed looking at my results as much as I enjoyed producing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
